{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "perfect-system",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow: v2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow: v\" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-buddy",
   "metadata": {},
   "source": [
    "## [Weight Clustering in Keras](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example)\n",
    "\n",
    "Clustering reduces the number of unique weight values in a model, leading to benefits for deployment. It first groups the weights of each layer into N clusters, then shares the cluster's centroid value for all the weights belonging to the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "herbal-proxy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "conscious-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-patch",
   "metadata": {},
   "source": [
    "### Train a tf.keras model for MNIST without clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "novel-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "synthetic-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images  = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "metallic-alexander",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "    keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation=tf.nn.relu),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "welcome-garage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.5263 - accuracy: 0.8562 - val_loss: 0.1018 - val_accuracy: 0.9740\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.0765 - val_accuracy: 0.9793\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 0.0668 - val_accuracy: 0.9822\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0614 - accuracy: 0.9821 - val_loss: 0.0672 - val_accuracy: 0.9822\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0528 - accuracy: 0.9843 - val_loss: 0.0664 - val_accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0515 - accuracy: 0.9850 - val_loss: 0.0607 - val_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0600 - val_accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 0.0663 - val_accuracy: 0.9825\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0363 - accuracy: 0.9900 - val_loss: 0.0625 - val_accuracy: 0.9837\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0597 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0a02b4d90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-shanghai",
   "metadata": {},
   "source": [
    "### Evaluate the baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "anticipated-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.982699990272522\n",
      "Saving model to:  /tmp/tmpne8p2j60.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-trainer",
   "metadata": {},
   "source": [
    "### Fine-tune the pre-trained model with clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "norwegian-speaking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cluster_reshape_5 (ClusterWe (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_3 (ClusterWei (None, 26, 26, 12)        136       \n",
      "_________________________________________________________________\n",
      "cluster_max_pooling2d_3 (Clu (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "cluster_flatten_3 (ClusterWe (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "cluster_dense_3 (ClusterWeig (None, 10)                20306     \n",
      "=================================================================\n",
      "Total params: 20,442\n",
      "Trainable params: 54\n",
      "Non-trainable params: 20,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = { \n",
    "    'number_of_clusters': 16,\n",
    "    'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-electric",
   "metadata": {},
   "source": [
    "### Comparing against the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "comparative-radiation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.0745 - val_accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd03c0a8f10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "exterior-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.982699990272522\n",
      "Clustered test accuracy: 0.9785000085830688\n"
     ]
    }
   ],
   "source": [
    "_, clustered_model_accuracy = clustered_model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Clustered test accuracy:', clustered_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-transcription",
   "metadata": {},
   "source": [
    "### Create 6x smaller models from clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "asian-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /tmp/tmpjn4bl2kr.h5\n"
     ]
    }
   ],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "constitutional-yield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbntkryx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwbntkryx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: /tmp/clustered_mnist.tflite\n"
     ]
    }
   ],
   "source": [
    "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "  f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "encouraging-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "demanding-barbados",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 78153.00 bytes\n",
      "Size of gzipped clustered Keras model: 13338.00 bytes\n",
      "Size of gzipped clustered TFlite model: 12686.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered Keras model: %.2f bytes\" % (get_gzipped_model_size(clustered_keras_file)))\n",
    "print(\"Size of gzipped clustered TFlite model: %.2f bytes\" % (get_gzipped_model_size(clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-celebrity",
   "metadata": {},
   "source": [
    "### Create an 8x smaller TFLite model from combining weight clustering and post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "plain-pointer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbxb0rrd5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbxb0rrd5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized and clustered TFLite model to: /tmp/tmp748o3_r0.tflite\n",
      "Size of gzipped baseline Keras model: 78153.00 bytes\n",
      "Size of gzipped clustered and quantized TFlite model: 9592.00 bytes\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "_, quantized_and_clustered_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_clustered_tflite_file, 'wb') as f:\n",
    "  f.write(tflite_quant_model)\n",
    "\n",
    "print('Saved quantized and clustered TFLite model to:', quantized_and_clustered_tflite_file)\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped clustered and quantized TFlite model: %.2f bytes\" % (get_gzipped_model_size(quantized_and_clustered_tflite_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-outdoors",
   "metadata": {},
   "source": [
    "### See the persistence of accuracy from TF to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "chronic-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hollywood-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Clustered and quantized TFLite test_accuracy: 0.9787\n",
      "Clustered TF test accuracy: 0.9785000085830688\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = eval_model(interpreter)\n",
    "\n",
    "print('Clustered and quantized TFLite test_accuracy:', test_accuracy)\n",
    "print('Clustered TF test accuracy:', clustered_model_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
